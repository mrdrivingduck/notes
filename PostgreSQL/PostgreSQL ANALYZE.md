# PostgreSQL - ANALYZE

Created by : Mr Dk.

2022 / 06 / 20 0:34

Hangzhou, Zhejiang, China

---

## Background

PostgreSQL åœ¨ä¼˜åŒ–å™¨ä¸­ä¸ºä¸€ä¸ªæŸ¥è¯¢æ ‘è¾“å‡ºä¸€ä¸ªæ‰§è¡Œæ•ˆç‡æœ€é«˜çš„ç‰©ç†è®¡åˆ’æ ‘ã€‚å…¶ä¸­ï¼Œæ‰§è¡Œæ•ˆç‡é«˜ä½çš„è¡¡é‡æ˜¯é€šè¿‡ä»£ä»·ä¼°ç®—å®ç°çš„ã€‚æ¯”å¦‚é€šè¿‡ä¼°ç®—æŸ¥è¯¢è¿”å›å…ƒç»„çš„æ¡æ•°ï¼Œå’Œå…ƒç»„çš„å®½åº¦ï¼Œå°±å¯ä»¥è®¡ç®—å‡º I/O å¼€é”€ï¼›ä¹Ÿå¯ä»¥æ ¹æ®å°†è¦æ‰§è¡Œçš„ç‰©ç†æ“ä½œä¼°ç®—å‡ºå¯èƒ½éœ€è¦æ¶ˆè€—çš„ CPU ä»£ä»·ã€‚ä¼˜åŒ–å™¨é€šè¿‡ç³»ç»Ÿè¡¨ `pg_statistic` è·å¾—è¿™äº›åœ¨ä»£ä»·ä¼°ç®—è¿‡ç¨‹éœ€è¦ä½¿ç”¨åˆ°çš„å…³é”®ç»Ÿè®¡ä¿¡æ¯ï¼Œè€Œ `pg_statistic` ç³»ç»Ÿè¡¨ä¸­çš„ç»Ÿè®¡ä¿¡æ¯åˆæ˜¯é€šè¿‡è‡ªåŠ¨æˆ–æ‰‹åŠ¨çš„ `ANALYZE` æ“ä½œï¼ˆæˆ– `VACUUM`ï¼‰è®¡ç®—å¾—åˆ°çš„ã€‚`ANALYZE` å°†ä¼šæ‰«æè¡¨ä¸­çš„æ•°æ®å¹¶æŒ‰åˆ—è¿›è¡Œåˆ†æï¼Œå°†å¾—åˆ°çš„è¯¸å¦‚æ¯åˆ—çš„æ•°æ®åˆ†å¸ƒã€æœ€å¸¸è§å€¼ã€é¢‘ç‡ç­‰ç»Ÿè®¡ä¿¡æ¯å†™å…¥ç³»ç»Ÿè¡¨ã€‚

æœ¬æ–‡ä»æºç çš„è§’åº¦åˆ†æä¸€ä¸‹ `ANALYZE` æ“ä½œçš„å®ç°æœºåˆ¶ã€‚æºç ä½¿ç”¨ç›®å‰ PostgreSQL æœ€æ–°çš„ç¨³å®šç‰ˆæœ¬ PostgreSQL 14ã€‚

## Statistics

é¦–å…ˆï¼Œæˆ‘ä»¬åº”å½“ææ˜ç™½åˆ†ææ“ä½œçš„è¾“å‡ºæ˜¯ä»€ä¹ˆã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥çœ‹ä¸€çœ‹ `pg_statistic` ä¸­æœ‰å“ªäº›åˆ—ï¼Œæ¯ä¸ªåˆ—çš„å«ä¹‰æ˜¯ä»€ä¹ˆã€‚è¿™ä¸ªç³»ç»Ÿè¡¨ä¸­çš„æ¯ä¸€è¡Œè¡¨ç¤ºå…¶å®ƒæ•°æ®è¡¨ä¸­ **æ¯ä¸€åˆ—çš„ç»Ÿè®¡ä¿¡æ¯**ã€‚

```sql
postgres=# \d+ pg_statistic
                                 Table "pg_catalog.pg_statistic"
   Column    |   Type   | Collation | Nullable | Default | Storage  | Stats target | Description
-------------+----------+-----------+----------+---------+----------+--------------+-------------
 starelid    | oid      |           | not null |         | plain    |              |
 staattnum   | smallint |           | not null |         | plain    |              |
 stainherit  | boolean  |           | not null |         | plain    |              |
 stanullfrac | real     |           | not null |         | plain    |              |
 stawidth    | integer  |           | not null |         | plain    |              |
 stadistinct | real     |           | not null |         | plain    |              |
 stakind1    | smallint |           | not null |         | plain    |              |
 stakind2    | smallint |           | not null |         | plain    |              |
 stakind3    | smallint |           | not null |         | plain    |              |
 stakind4    | smallint |           | not null |         | plain    |              |
 stakind5    | smallint |           | not null |         | plain    |              |
 staop1      | oid      |           | not null |         | plain    |              |
 staop2      | oid      |           | not null |         | plain    |              |
 staop3      | oid      |           | not null |         | plain    |              |
 staop4      | oid      |           | not null |         | plain    |              |
 staop5      | oid      |           | not null |         | plain    |              |
 stanumbers1 | real[]   |           |          |         | extended |              |
 stanumbers2 | real[]   |           |          |         | extended |              |
 stanumbers3 | real[]   |           |          |         | extended |              |
 stanumbers4 | real[]   |           |          |         | extended |              |
 stanumbers5 | real[]   |           |          |         | extended |              |
 stavalues1  | anyarray |           |          |         | extended |              |
 stavalues2  | anyarray |           |          |         | extended |              |
 stavalues3  | anyarray |           |          |         | extended |              |
 stavalues4  | anyarray |           |          |         | extended |              |
 stavalues5  | anyarray |           |          |         | extended |              |
Indexes:
    "pg_statistic_relid_att_inh_index" UNIQUE, btree (starelid, staattnum, stainherit)
```

```c
/* ----------------
 *      pg_statistic definition.  cpp turns this into
 *      typedef struct FormData_pg_statistic
 * ----------------
 */
CATALOG(pg_statistic,2619,StatisticRelationId)
{
    /* These fields form the unique key for the entry: */
    Oid         starelid BKI_LOOKUP(pg_class);  /* relation containing
                                                 * attribute */
    int16       staattnum;      /* attribute (column) stats are for */
    bool        stainherit;     /* true if inheritance children are included */

    /* the fraction of the column's entries that are NULL: */
    float4      stanullfrac;

    /*
     * stawidth is the average width in bytes of non-null entries.  For
     * fixed-width datatypes this is of course the same as the typlen, but for
     * var-width types it is more useful.  Note that this is the average width
     * of the data as actually stored, post-TOASTing (eg, for a
     * moved-out-of-line value, only the size of the pointer object is
     * counted).  This is the appropriate definition for the primary use of
     * the statistic, which is to estimate sizes of in-memory hash tables of
     * tuples.
     */
    int32       stawidth;

    /* ----------------
     * stadistinct indicates the (approximate) number of distinct non-null
     * data values in the column.  The interpretation is:
     *      0       unknown or not computed
     *      > 0     actual number of distinct values
     *      < 0     negative of multiplier for number of rows
     * The special negative case allows us to cope with columns that are
     * unique (stadistinct = -1) or nearly so (for example, a column in which
     * non-null values appear about twice on the average could be represented
     * by stadistinct = -0.5 if there are no nulls, or -0.4 if 20% of the
     * column is nulls).  Because the number-of-rows statistic in pg_class may
     * be updated more frequently than pg_statistic is, it's important to be
     * able to describe such situations as a multiple of the number of rows,
     * rather than a fixed number of distinct values.  But in other cases a
     * fixed number is correct (eg, a boolean column).
     * ----------------
     */
    float4      stadistinct;

    /* ----------------
     * To allow keeping statistics on different kinds of datatypes,
     * we do not hard-wire any particular meaning for the remaining
     * statistical fields.  Instead, we provide several "slots" in which
     * statistical data can be placed.  Each slot includes:
     *      kind            integer code identifying kind of data (see below)
     *      op              OID of associated operator, if needed
     *      coll            OID of relevant collation, or 0 if none
     *      numbers         float4 array (for statistical values)
     *      values          anyarray (for representations of data values)
     * The ID, operator, and collation fields are never NULL; they are zeroes
     * in an unused slot.  The numbers and values fields are NULL in an
     * unused slot, and might also be NULL in a used slot if the slot kind
     * has no need for one or the other.
     * ----------------
     */

    int16       stakind1;
    int16       stakind2;
    int16       stakind3;
    int16       stakind4;
    int16       stakind5;

    Oid         staop1 BKI_LOOKUP_OPT(pg_operator);
    Oid         staop2 BKI_LOOKUP_OPT(pg_operator);
    Oid         staop3 BKI_LOOKUP_OPT(pg_operator);
    Oid         staop4 BKI_LOOKUP_OPT(pg_operator);
    Oid         staop5 BKI_LOOKUP_OPT(pg_operator);

    Oid         stacoll1 BKI_LOOKUP_OPT(pg_collation);
    Oid         stacoll2 BKI_LOOKUP_OPT(pg_collation);
    Oid         stacoll3 BKI_LOOKUP_OPT(pg_collation);
    Oid         stacoll4 BKI_LOOKUP_OPT(pg_collation);
    Oid         stacoll5 BKI_LOOKUP_OPT(pg_collation);

#ifdef CATALOG_VARLEN           /* variable-length fields start here */
    float4      stanumbers1[1];
    float4      stanumbers2[1];
    float4      stanumbers3[1];
    float4      stanumbers4[1];
    float4      stanumbers5[1];

    /*
     * Values in these arrays are values of the column's data type, or of some
     * related type such as an array element type.  We presently have to cheat
     * quite a bit to allow polymorphic arrays of this kind, but perhaps
     * someday it'll be a less bogus facility.
     */
    anyarray    stavalues1;
    anyarray    stavalues2;
    anyarray    stavalues3;
    anyarray    stavalues4;
    anyarray    stavalues5;
#endif
} FormData_pg_statistic;
```

ä»æ•°æ®åº“å‘½ä»¤è¡Œçš„è§’åº¦å’Œå†…æ ¸ C ä»£ç çš„è§’åº¦æ¥çœ‹ï¼Œç»Ÿè®¡ä¿¡æ¯çš„å†…å®¹éƒ½æ˜¯ä¸€è‡´çš„ã€‚æ‰€æœ‰çš„å±æ€§éƒ½ä»¥ `sta` å¼€å¤´ã€‚å…¶ä¸­ï¼š

- `starelid` è¡¨ç¤ºå½“å‰åˆ—æ‰€å±çš„è¡¨æˆ–ç´¢å¼•
- `staattnum` è¡¨ç¤ºæœ¬è¡Œç»Ÿè®¡ä¿¡æ¯å±äºä¸Šè¿°è¡¨æˆ–ç´¢å¼•ä¸­çš„ç¬¬å‡ åˆ—
- `stainherit` è¡¨ç¤ºç»Ÿè®¡ä¿¡æ¯æ˜¯å¦åŒ…å«å­åˆ—
- `stanullfrac` è¡¨ç¤ºè¯¥åˆ—ä¸­å€¼ä¸º NULL çš„è¡Œæ•°æ¯”ä¾‹
- `stawidth` è¡¨ç¤ºè¯¥åˆ—éç©ºå€¼çš„å¹³å‡å®½åº¦
- `stadistinct` è¡¨ç¤ºåˆ—ä¸­éç©ºå€¼çš„å”¯ä¸€å€¼æ•°é‡
  - `0` è¡¨ç¤ºæœªçŸ¥æˆ–æœªè®¡ç®—
  - `> 0` è¡¨ç¤ºå”¯ä¸€å€¼çš„å®é™…æ•°é‡
  - `< 0` è¡¨ç¤º _negative of multiplier for number of rows_ ï¼Ÿå•¥ç™»è¥¿ ğŸ˜©

ç”±äºä¸åŒæ•°æ®ç±»å‹æ‰€èƒ½å¤Ÿè¢«è®¡ç®—çš„ç»Ÿè®¡ä¿¡æ¯å¯èƒ½ä¼šæœ‰ä¸€äº›ç»†å¾®çš„å·®åˆ«ï¼Œåœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ä¸­ï¼ŒPostgreSQL é¢„ç•™äº†ä¸€äº›å­˜æ”¾ç»Ÿè®¡ä¿¡æ¯çš„ **æ§½ï¼ˆslotsï¼‰**ã€‚ç›®å‰çš„å†…æ ¸é‡Œæš‚æ—¶é¢„ç•™äº†äº”ä¸ªæ§½ï¼š

```c
#define STATISTIC_NUM_SLOTS  5
```

æ¯ä¸€ç§ç‰¹å®šçš„ç»Ÿè®¡ä¿¡æ¯å¯ä»¥ä½¿ç”¨ä¸€ä¸ªæ§½ï¼Œå…·ä½“åœ¨æ§½é‡Œæ”¾ä»€ä¹ˆå®Œå…¨ç”±è¿™ç§ç»Ÿè®¡ä¿¡æ¯çš„å®šä¹‰è‡ªç”±å†³å®šã€‚æ¯ä¸€ä¸ªæ§½çš„å¯ç”¨ç©ºé—´åŒ…å«è¿™ä¹ˆå‡ ä¸ªéƒ¨åˆ†ï¼ˆå…¶ä¸­çš„ `N` è¡¨ç¤ºæ§½çš„ç¼–å·ï¼Œå–å€¼ä¸º `1` åˆ° `5`ï¼‰ï¼š

- `stakindN`ï¼šæ ‡è¯†è¿™ç§ç»Ÿè®¡ä¿¡æ¯çš„æ•´æ•°ç¼–å·
- `staopN`ï¼šç”¨äºè®¡ç®—æˆ–ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯çš„è¿ç®—ç¬¦ OID
- `stacollN`ï¼šæ’åºè§„åˆ™ OID
- `stanumbersN`ï¼šæµ®ç‚¹æ•°æ•°ç»„
- `stavaluesN`ï¼šä»»æ„å€¼æ•°ç»„

PostgreSQL å†…æ ¸ä¸­è§„å®šï¼Œç»Ÿè®¡ä¿¡æ¯çš„ç¼–å· `1` è‡³ `99` è¢«ä¿ç•™ç»™ PostgreSQL æ ¸å¿ƒç»Ÿè®¡ä¿¡æ¯ä½¿ç”¨ï¼Œå…¶å®ƒéƒ¨åˆ†çš„ç¼–å·å®‰æ’å¦‚å†…æ ¸æ³¨é‡Šæ‰€ç¤ºï¼š

```c
/*
 * The present allocation of "kind" codes is:
 *
 *  1-99:       reserved for assignment by the core PostgreSQL project
 *              (values in this range will be documented in this file)
 *  100-199:    reserved for assignment by the PostGIS project
 *              (values to be documented in PostGIS documentation)
 *  200-299:    reserved for assignment by the ESRI ST_Geometry project
 *              (values to be documented in ESRI ST_Geometry documentation)
 *  300-9999:   reserved for future public assignments
 *
 * For private use you may choose a "kind" code at random in the range
 * 10000-30000.  However, for code that is to be widely disseminated it is
 * better to obtain a publicly defined "kind" code by request from the
 * PostgreSQL Global Development Group.
 */
```

ç›®å‰å¯ä»¥åœ¨å†…æ ¸ä»£ç ä¸­çœ‹åˆ°çš„ PostgreSQL æ ¸å¿ƒç»Ÿè®¡ä¿¡æ¯æœ‰ 7 ä¸ªï¼Œç¼–å·åˆ†åˆ«ä» `1` åˆ° `7`ã€‚æˆ‘ä»¬å¯ä»¥çœ‹çœ‹è¿™ 7 ç§ç»Ÿè®¡ä¿¡æ¯åˆ†åˆ«å¦‚ä½•ä½¿ç”¨ä¸Šè¿°çš„æ§½ã€‚

### Most Common Values (MCV)

```c
/*
 * In a "most common values" slot, staop is the OID of the "=" operator
 * used to decide whether values are the same or not, and stacoll is the
 * collation used (same as column's collation).  stavalues contains
 * the K most common non-null values appearing in the column, and stanumbers
 * contains their frequencies (fractions of total row count).  The values
 * shall be ordered in decreasing frequency.  Note that since the arrays are
 * variable-size, K may be chosen by the statistics collector.  Values should
 * not appear in MCV unless they have been observed to occur more than once;
 * a unique column will have no MCV slot.
 */
#define STATISTIC_KIND_MCV  1
```

å¯¹äºä¸€ä¸ªåˆ—ä¸­çš„ **æœ€å¸¸è§å€¼**ï¼Œåœ¨ `staop` ä¸­ä¿å­˜ `=` è¿ç®—ç¬¦æ¥å†³å®šä¸€ä¸ªå€¼æ˜¯å¦ç­‰äºä¸€ä¸ªæœ€å¸¸è§å€¼ã€‚åœ¨ `stavalues` ä¸­ä¿å­˜äº†è¯¥åˆ—ä¸­æœ€å¸¸è§çš„ K ä¸ªéç©ºå€¼ï¼Œ`stanumbers` ä¸­åˆ†åˆ«ä¿å­˜äº†è¿™ K ä¸ªå€¼å‡ºç°çš„é¢‘ç‡ã€‚

### Histogram

```c
/*
 * A "histogram" slot describes the distribution of scalar data.  staop is
 * the OID of the "<" operator that describes the sort ordering, and stacoll
 * is the relevant collation.  (In theory more than one histogram could appear,
 * if a datatype has more than one useful sort operator or we care about more
 * than one collation.  Currently the collation will always be that of the
 * underlying column.)  stavalues contains M (>=2) non-null values that
 * divide the non-null column data values into M-1 bins of approximately equal
 * population.  The first stavalues item is the MIN and the last is the MAX.
 * stanumbers is not used and should be NULL.  IMPORTANT POINT: if an MCV
 * slot is also provided, then the histogram describes the data distribution
 * *after removing the values listed in MCV* (thus, it's a "compressed
 * histogram" in the technical parlance).  This allows a more accurate
 * representation of the distribution of a column with some very-common
 * values.  In a column with only a few distinct values, it's possible that
 * the MCV list describes the entire data population; in this case the
 * histogram reduces to empty and should be omitted.
 */
#define STATISTIC_KIND_HISTOGRAM  2
```

è¡¨ç¤ºä¸€ä¸ªï¼ˆæ•°å€¼ï¼‰åˆ—çš„æ•°æ®åˆ†å¸ƒç›´æ–¹å›¾ã€‚`staop` ä¿å­˜ `<` è¿ç®—ç¬¦ç”¨äºå†³å®šæ•°æ®åˆ†å¸ƒçš„æ’åºé¡ºåºã€‚`stavalues` åŒ…å«äº†èƒ½å¤Ÿå°†è¯¥åˆ—çš„éç©ºå€¼åˆ’åˆ†åˆ° M - 1 ä¸ªå®¹é‡æ¥è¿‘çš„æ¡¶ä¸­çš„ M ä¸ªéç©ºå€¼ã€‚å¦‚æœè¯¥åˆ—ä¸­å·²ç»æœ‰äº† MCV çš„æ§½ï¼Œé‚£ä¹ˆæ•°æ®åˆ†å¸ƒç›´æ–¹å›¾ä¸­å°†ä¸åŒ…å« MCV ä¸­çš„å€¼ï¼Œä»¥è·å¾—æ›´ç²¾ç¡®çš„æ•°æ®åˆ†å¸ƒã€‚

### Correlation

```c
/*
 * A "correlation" slot describes the correlation between the physical order
 * of table tuples and the ordering of data values of this column, as seen
 * by the "<" operator identified by staop with the collation identified by
 * stacoll.  (As with the histogram, more than one entry could theoretically
 * appear.)  stavalues is not used and should be NULL.  stanumbers contains
 * a single entry, the correlation coefficient between the sequence of data
 * values and the sequence of their actual tuple positions.  The coefficient
 * ranges from +1 to -1.
 */
#define STATISTIC_KIND_CORRELATION  3
```

åœ¨ `stanumbers` ä¸­ä¿å­˜æ•°æ®å€¼å’Œå®ƒä»¬çš„å®é™…å…ƒç»„ä½ç½®çš„ç›¸å…³ç³»æ•°ã€‚

### Most Common Elements

```c
/*
 * A "most common elements" slot is similar to a "most common values" slot,
 * except that it stores the most common non-null *elements* of the column
 * values.  This is useful when the column datatype is an array or some other
 * type with identifiable elements (for instance, tsvector).  staop contains
 * the equality operator appropriate to the element type, and stacoll
 * contains the collation to use with it.  stavalues contains
 * the most common element values, and stanumbers their frequencies.  Unlike
 * MCV slots, frequencies are measured as the fraction of non-null rows the
 * element value appears in, not the frequency of all rows.  Also unlike
 * MCV slots, the values are sorted into the element type's default order
 * (to support binary search for a particular value).  Since this puts the
 * minimum and maximum frequencies at unpredictable spots in stanumbers,
 * there are two extra members of stanumbers, holding copies of the minimum
 * and maximum frequencies.  Optionally, there can be a third extra member,
 * which holds the frequency of null elements (expressed in the same terms:
 * the fraction of non-null rows that contain at least one null element).  If
 * this member is omitted, the column is presumed to contain no null elements.
 *
 * Note: in current usage for tsvector columns, the stavalues elements are of
 * type text, even though their representation within tsvector is not
 * exactly text.
 */
#define STATISTIC_KIND_MCELEM  4
```

ä¸ MCV ç±»ä¼¼ï¼Œä½†æ˜¯ä¿å­˜çš„æ˜¯åˆ—ä¸­çš„ **æœ€å¸¸è§å…ƒç´ **ï¼Œä¸»è¦ç”¨äºæ•°ç»„ç­‰ç±»å‹ã€‚åŒæ ·ï¼Œåœ¨ `staop` ä¸­ä¿å­˜äº†ç­‰å€¼è¿ç®—ç¬¦ç”¨äºåˆ¤æ–­å…ƒç´ å‡ºç°çš„é¢‘ç‡é«˜ä½ã€‚ä½†ä¸ MCV ä¸åŒçš„æ˜¯è¿™é‡Œçš„é¢‘ç‡è®¡ç®—çš„åˆ†æ¯æ˜¯éç©ºçš„è¡Œï¼Œè€Œä¸æ˜¯æ‰€æœ‰çš„è¡Œã€‚å¦å¤–ï¼Œæ‰€æœ‰çš„å¸¸è§å…ƒç´ ä½¿ç”¨å…ƒç´ å¯¹åº”æ•°æ®ç±»å‹çš„é»˜è®¤é¡ºåºè¿›è¡Œæ’åºï¼Œä»¥ä¾¿äºŒåˆ†æŸ¥æ‰¾ã€‚

### Distinct Elements Count Histogram

```c
/*
 * A "distinct elements count histogram" slot describes the distribution of
 * the number of distinct element values present in each row of an array-type
 * column.  Only non-null rows are considered, and only non-null elements.
 * staop contains the equality operator appropriate to the element type,
 * and stacoll contains the collation to use with it.
 * stavalues is not used and should be NULL.  The last member of stanumbers is
 * the average count of distinct element values over all non-null rows.  The
 * preceding M (>=2) members form a histogram that divides the population of
 * distinct-elements counts into M-1 bins of approximately equal population.
 * The first of these is the minimum observed count, and the last the maximum.
 */
#define STATISTIC_KIND_DECHIST  5
```

è¡¨ç¤ºåˆ—ä¸­å‡ºç°æ‰€æœ‰æ•°å€¼çš„é¢‘ç‡åˆ†å¸ƒç›´æ–¹å›¾ã€‚`stanumbers` æ•°ç»„çš„å‰ M ä¸ªå…ƒç´ æ˜¯å°†åˆ—ä¸­æ‰€æœ‰å”¯ä¸€å€¼çš„å‡ºç°æ¬¡æ•°å¤§è‡´å‡åˆ†åˆ° M - 1 ä¸ªæ¡¶ä¸­çš„è¾¹ç•Œå€¼ã€‚åç»­è·Ÿä¸Šä¸€ä¸ªæ‰€æœ‰å”¯ä¸€å€¼çš„å¹³å‡å‡ºç°æ¬¡æ•°ã€‚è¿™ä¸ªç»Ÿè®¡ä¿¡æ¯åº”è¯¥ä¼šè¢«ç”¨äºè®¡ç®— _é€‰æ‹©ç‡_ã€‚

### Length Histogram

```c
/*
 * A "length histogram" slot describes the distribution of range lengths in
 * rows of a range-type column. stanumbers contains a single entry, the
 * fraction of empty ranges. stavalues is a histogram of non-empty lengths, in
 * a format similar to STATISTIC_KIND_HISTOGRAM: it contains M (>=2) range
 * values that divide the column data values into M-1 bins of approximately
 * equal population. The lengths are stored as float8s, as measured by the
 * range type's subdiff function. Only non-null rows are considered.
 */
#define STATISTIC_KIND_RANGE_LENGTH_HISTOGRAM  6
```

é•¿åº¦ç›´æ–¹å›¾æè¿°äº†ä¸€ä¸ªèŒƒå›´ç±»å‹çš„åˆ—çš„èŒƒå›´é•¿åº¦åˆ†å¸ƒã€‚åŒæ ·ä¹Ÿæ˜¯ä¸€ä¸ªé•¿åº¦ä¸º M çš„ç›´æ–¹å›¾ï¼Œä¿å­˜åœ¨ `stanumbers` ä¸­ã€‚

### Bounds Histogram

```c
/*
 * A "bounds histogram" slot is similar to STATISTIC_KIND_HISTOGRAM, but for
 * a range-type column.  stavalues contains M (>=2) range values that divide
 * the column data values into M-1 bins of approximately equal population.
 * Unlike a regular scalar histogram, this is actually two histograms combined
 * into a single array, with the lower bounds of each value forming a
 * histogram of lower bounds, and the upper bounds a histogram of upper
 * bounds.  Only non-NULL, non-empty ranges are included.
 */
#define STATISTIC_KIND_BOUNDS_HISTOGRAM  7
```

è¾¹ç•Œç›´æ–¹å›¾åŒæ ·ä¹Ÿè¢«ç”¨äºèŒƒå›´ç±»å‹ï¼Œä¸æ•°æ®åˆ†å¸ƒç›´æ–¹å›¾ç±»ä¼¼ã€‚`stavalues` ä¸­ä¿å­˜äº†ä½¿è¯¥åˆ—æ•°å€¼å¤§è‡´å‡åˆ†åˆ° M - 1 ä¸ªæ¡¶ä¸­çš„ M ä¸ªèŒƒå›´è¾¹ç•Œå€¼ã€‚åªè€ƒè™‘éç©ºè¡Œã€‚

## Kernel Execution of Analyze

çŸ¥é“ `pg_statistic` æœ€ç»ˆéœ€è¦ä¿å­˜å“ªäº›ä¿¡æ¯ä»¥åï¼Œå†æ¥çœ‹çœ‹å†…æ ¸å¦‚ä½•æ”¶é›†å’Œè®¡ç®—è¿™äº›ä¿¡æ¯ã€‚è®©æˆ‘ä»¬è¿›å…¥ PostgreSQL å†…æ ¸çš„æ‰§è¡Œå™¨ä»£ç ä¸­ã€‚å¯¹äº `ANALYZE` è¿™ç§å·¥å…·æ€§è´¨çš„æŒ‡ä»¤ï¼Œæ‰§è¡Œå™¨ä»£ç é€šè¿‡ `standard_ProcessUtility()` å‡½æ•°ä¸­çš„ switch case å°†æ¯ä¸€ç§æŒ‡ä»¤è·¯ç”±åˆ°å®ç°ç›¸åº”åŠŸèƒ½çš„å‡½æ•°ä¸­ã€‚

```c
/*
 * standard_ProcessUtility itself deals only with utility commands for
 * which we do not provide event trigger support.  Commands that do have
 * such support are passed down to ProcessUtilitySlow, which contains the
 * necessary infrastructure for such triggers.
 *
 * This division is not just for performance: it's critical that the
 * event trigger code not be invoked when doing START TRANSACTION for
 * example, because we might need to refresh the event trigger cache,
 * which requires being in a valid transaction.
 */
void
standard_ProcessUtility(PlannedStmt *pstmt,
                        const char *queryString,
                        bool readOnlyTree,
                        ProcessUtilityContext context,
                        ParamListInfo params,
                        QueryEnvironment *queryEnv,
                        DestReceiver *dest,
                        QueryCompletion *qc)
{
    // ...

    switch (nodeTag(parsetree))
    {
        // ...

        case T_VacuumStmt:
            ExecVacuum(pstate, (VacuumStmt *) parsetree, isTopLevel);
            break;

        // ...
    }

    // ...
}
```

`ANALYZE` çš„å¤„ç†é€»è¾‘å…¥å£å’Œ `VACUUM` ä¸€è‡´ï¼Œè¿›å…¥ `ExecVacuum()` å‡½æ•°ã€‚

```c
/*
 * Primary entry point for manual VACUUM and ANALYZE commands
 *
 * This is mainly a preparation wrapper for the real operations that will
 * happen in vacuum().
 */
void
ExecVacuum(ParseState *pstate, VacuumStmt *vacstmt, bool isTopLevel)
{
    // ...

    /* Now go through the common routine */
    vacuum(vacstmt->rels, &params, NULL, isTopLevel);
}
```

åœ¨ parse äº†ä¸€å¤§å † option ä¹‹åï¼Œè¿›å…¥äº† `vacuum()` å‡½æ•°ã€‚åœ¨è¿™é‡Œï¼Œå†…æ ¸ä»£ç å°†ä¼šé¦–å…ˆæ˜ç¡®ä¸€ä¸‹è¦åˆ†æå“ªäº›è¡¨ã€‚å› ä¸º `ANALYZE` å‘½ä»¤åœ¨ä½¿ç”¨ä¸Šå¯ä»¥ï¼š

- åˆ†ææ•´ä¸ªæ•°æ®åº“ä¸­çš„æ‰€æœ‰è¡¨
- åˆ†ææŸå‡ ä¸ªç‰¹å®šçš„è¡¨
- åˆ†ææŸä¸ªè¡¨çš„æŸå‡ ä¸ªç‰¹å®šåˆ—

åœ¨æ˜ç¡®è¦åˆ†æå“ªäº›è¡¨ä»¥åï¼Œä¾æ¬¡å°†æ¯ä¸€ä¸ªè¡¨ä¼ å…¥ `analyze_rel()` å‡½æ•°ï¼š

```c
if (params->options & VACOPT_ANALYZE)
{
    // ...

    analyze_rel(vrel->oid, vrel->relation, params,
                vrel->va_cols, in_outer_xact, vac_strategy);

    // ...
}
```

è¿›å…¥ `analyze_rel()` å‡½æ•°ä»¥åï¼Œå†…æ ¸ä»£ç å°†ä¼šå¯¹å°†è¦è¢«åˆ†æçš„è¡¨åŠ  `ShareUpdateExclusiveLock` é”ï¼Œä»¥é˜²æ­¢ä¸¤ä¸ªå¹¶å‘è¿›è¡Œçš„ `ANALYZE`ã€‚ç„¶åæ ¹æ®å¾…åˆ†æè¡¨çš„ç±»å‹æ¥å†³å®šå…·ä½“çš„å¤„ç†æ–¹å¼ï¼ˆæ¯”å¦‚åˆ†æä¸€ä¸ª FDW å¤–è¡¨å°±åº”è¯¥ç›´æ¥è°ƒç”¨ FDW routine ä¸­æä¾›çš„ ANALYZE åŠŸèƒ½äº†ï¼‰ã€‚æ¥ä¸‹æ¥ï¼Œå°†è¿™ä¸ªè¡¨ä¼ å…¥ `do_analyze_rel()` å‡½æ•°ä¸­ã€‚

```c
/*
 *  analyze_rel() -- analyze one relation
 *
 * relid identifies the relation to analyze.  If relation is supplied, use
 * the name therein for reporting any failure to open/lock the rel; do not
 * use it once we've successfully opened the rel, since it might be stale.
 */
void
analyze_rel(Oid relid, RangeVar *relation,
            VacuumParams *params, List *va_cols, bool in_outer_xact,
            BufferAccessStrategy bstrategy)
{
    // ...

    /*
     * Do the normal non-recursive ANALYZE.  We can skip this for partitioned
     * tables, which don't contain any rows.
     */
    if (onerel->rd_rel->relkind != RELKIND_PARTITIONED_TABLE)
        do_analyze_rel(onerel, params, va_cols, acquirefunc,
                       relpages, false, in_outer_xact, elevel);

    // ...
}
```

è¿›å…¥ `do_analyze_rel()` å‡½æ•°åï¼Œå†…æ ¸ä»£ç å°†è¿›ä¸€æ­¥æ˜ç¡®è¦åˆ†æä¸€ä¸ªè¡¨ä¸­çš„å“ªäº›åˆ—ï¼šç”¨æˆ·å¯èƒ½æŒ‡å®šåªåˆ†æè¡¨ä¸­çš„æŸå‡ ä¸ªåˆ—â€”â€”è¢«é¢‘ç¹è®¿é—®çš„åˆ—æ‰æ›´æœ‰è¢«åˆ†æçš„ä»·å€¼ã€‚ç„¶åè¿˜è¦æ‰“å¼€å¾…åˆ†æè¡¨çš„æ‰€æœ‰ç´¢å¼•ï¼Œçœ‹çœ‹æ˜¯å¦æœ‰å¯ä»¥è¢«åˆ†æçš„åˆ—ã€‚

ä¸ºäº†å¾—åˆ°æ¯ä¸€åˆ—çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œæ˜¾ç„¶æˆ‘ä»¬éœ€è¦æŠŠæ¯ä¸€åˆ—çš„æ•°æ®ä»ç£ç›˜ä¸Šè¯»èµ·æ¥å†å»åšè®¡ç®—ã€‚è¿™é‡Œå°±æœ‰ä¸€ä¸ªæ¯”è¾ƒå…³é”®çš„é—®é¢˜äº†ï¼šåˆ°åº•æ‰«æå¤šå°‘è¡Œæ•°æ®å‘¢ï¼Ÿç†è®ºä¸Šï¼Œåˆ†æå°½å¯èƒ½å¤šçš„æ•°æ®ï¼Œæœ€å¥½æ˜¯å…¨éƒ¨çš„æ•°æ®ï¼Œè‚¯å®šèƒ½å¤Ÿå¾—åˆ°æœ€ç²¾ç¡®çš„ç»Ÿè®¡æ•°æ®ï¼›ä½†æ˜¯å¯¹ä¸€å¼ å¾ˆå¤§çš„è¡¨æ¥è¯´ï¼Œæˆ‘ä»¬æ²¡æœ‰åŠæ³•åœ¨å†…å­˜ä¸­æ”¾ä¸‹æ‰€æœ‰çš„æ•°æ®ï¼Œå¹¶ä¸”åˆ†æçš„é˜»å¡æ—¶é—´ä¹Ÿæ˜¯ä¸å¯æ¥å—çš„ã€‚æ‰€ä»¥ç”¨æˆ·å¯ä»¥æŒ‡å®šè¦é‡‡æ ·çš„æœ€å¤§è¡Œæ•°ï¼Œä»è€Œåœ¨è¿è¡Œå¼€é”€å’Œç»Ÿè®¡ä¿¡æ¯å‡†ç¡®æ€§ä¸Šè¾¾æˆå¦¥åï¼š

> é€šè¿‡è®¾ç½® GUC å‚æ•° [`default_statistics_target`](https://www.postgresql.org/docs/current/runtime-config-query.html#GUC-DEFAULT-STATISTICS-TARGET) ä¸ºæ›´å¤§çš„å€¼ï¼Œå¯ä»¥å…¨å±€å¢å¤§é‡‡æ ·çš„æ•°æ®é‡ã€‚è¿™ä¼šå¯¼è‡´ `ANALYZE` æ‰€éœ€è¦çš„æ•´ä½“æ—¶é—´å˜é•¿ï¼Œä½†å¯ä»¥å¾—åˆ°æ›´å‡†ç¡®çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆå°¤å…¶æ˜¯å¯¹å¤§è¡¨ï¼‰ã€‚å¦‚æœå…¨å±€è®¾ç½®å¸¦æ¥çš„å½±å“è¾ƒå¤§ï¼Œå¯ä»¥é€šè¿‡ [`ALTER TABLE ... ALTER COLUMN ... SET STATISTICS`](https://www.postgresql.org/docs/current/sql-altertable.html) ä¸ºæŸä¸€ä¸ªåˆ—å•ç‹¬è®¾ç½®é‡‡æ ·æ•°æ®é‡ã€‚

```c
/*
 * Determine how many rows we need to sample, using the worst case from
 * all analyzable columns.  We use a lower bound of 100 rows to avoid
 * possible overflow in Vitter's algorithm.  (Note: that will also be the
 * target in the corner case where there are no analyzable columns.)
 */
targrows = 100;
for (i = 0; i < attr_cnt; i++)
{
    if (targrows < vacattrstats[i]->minrows)
        targrows = vacattrstats[i]->minrows;
}
for (ind = 0; ind < nindexes; ind++)
{
    AnlIndexData *thisdata = &indexdata[ind];

    for (i = 0; i < thisdata->attr_cnt; i++)
    {
        if (targrows < thisdata->vacattrstats[i]->minrows)
            targrows = thisdata->vacattrstats[i]->minrows;
    }
}

/*
 * Look at extended statistics objects too, as those may define custom
 * statistics target. So we may need to sample more rows and then build
 * the statistics with enough detail.
 */
minrows = ComputeExtStatisticsRows(onerel, attr_cnt, vacattrstats);

if (targrows < minrows)
    targrows = minrows;
```

åœ¨ç¡®å®šéœ€è¦é‡‡æ ·å¤šå°‘è¡Œæ•°æ®åï¼Œå†…æ ¸ä»£ç åˆ†é…äº†ä¸€å—ç›¸åº”é•¿åº¦çš„å…ƒç»„æ•°ç»„ï¼Œç„¶åå¼€å§‹ä½¿ç”¨ `acquirefunc` å‡½æ•°æŒ‡é’ˆé‡‡æ ·æ•°æ®ï¼š

```c
/*
 * Acquire the sample rows
 */
rows = (HeapTuple *) palloc(targrows * sizeof(HeapTuple));
pgstat_progress_update_param(PROGRESS_ANALYZE_PHASE,
                             inh ? PROGRESS_ANALYZE_PHASE_ACQUIRE_SAMPLE_ROWS_INH :
                             PROGRESS_ANALYZE_PHASE_ACQUIRE_SAMPLE_ROWS);
if (inh)
    numrows = acquire_inherited_sample_rows(onerel, elevel,
                                            rows, targrows,
                                            &totalrows, &totaldeadrows);
else
    numrows = (*acquirefunc) (onerel, elevel,
                              rows, targrows,
                              &totalrows, &totaldeadrows);
```

è¿™ä¸ªå‡½æ•°æŒ‡é’ˆæŒ‡å‘çš„æ˜¯ `analyze_rel()` å‡½æ•°ä¸­è®¾ç½®å¥½çš„ `acquire_sample_rows()` å‡½æ•°ã€‚è¯¥å‡½æ•°ä½¿ç”¨ä¸¤é˜¶æ®µæ¨¡å¼å¯¹è¡¨ä¸­çš„æ•°æ®è¿›è¡Œé‡‡æ ·ï¼š

- é˜¶æ®µ 1ï¼šéšæœºé€‰æ‹©åŒ…å«ç›®æ ‡é‡‡æ ·è¡Œæ•°çš„æ•°æ®å—
- é˜¶æ®µ 2ï¼šå¯¹æ¯ä¸€ä¸ªæ•°æ®å—ä½¿ç”¨ Vitter ç®—æ³•æŒ‰è¡Œéšæœºé‡‡æ ·æ•°æ®

ä¸¤é˜¶æ®µåŒæ—¶è¿›è¡Œã€‚åœ¨é‡‡æ ·å®Œæˆåï¼Œè¢«é‡‡æ ·åˆ°çš„å…ƒç»„åº”è¯¥å·²ç»è¢«æ”¾ç½®åœ¨å…ƒç»„æ•°ç»„ä¸­äº†ã€‚å¯¹è¿™ä¸ªå…ƒç»„æ•°ç»„æŒ‰ç…§å…ƒç»„çš„ä½ç½®è¿›è¡Œå¿«é€Ÿæ’åºï¼Œå¹¶ä½¿ç”¨è¿™äº›é‡‡æ ·åˆ°çš„æ•°æ®ä¼°ç®—æ•´ä¸ªè¡¨ä¸­çš„å­˜æ´»å…ƒç»„ä¸æ­»å…ƒç»„çš„ä¸ªæ•°ï¼š

```c
/*
 * acquire_sample_rows -- acquire a random sample of rows from the table
 *
 * Selected rows are returned in the caller-allocated array rows[], which
 * must have at least targrows entries.
 * The actual number of rows selected is returned as the function result.
 * We also estimate the total numbers of live and dead rows in the table,
 * and return them into *totalrows and *totaldeadrows, respectively.
 *
 * The returned list of tuples is in order by physical position in the table.
 * (We will rely on this later to derive correlation estimates.)
 *
 * As of May 2004 we use a new two-stage method:  Stage one selects up
 * to targrows random blocks (or all blocks, if there aren't so many).
 * Stage two scans these blocks and uses the Vitter algorithm to create
 * a random sample of targrows rows (or less, if there are less in the
 * sample of blocks).  The two stages are executed simultaneously: each
 * block is processed as soon as stage one returns its number and while
 * the rows are read stage two controls which ones are to be inserted
 * into the sample.
 *
 * Although every row has an equal chance of ending up in the final
 * sample, this sampling method is not perfect: not every possible
 * sample has an equal chance of being selected.  For large relations
 * the number of different blocks represented by the sample tends to be
 * too small.  We can live with that for now.  Improvements are welcome.
 *
 * An important property of this sampling method is that because we do
 * look at a statistically unbiased set of blocks, we should get
 * unbiased estimates of the average numbers of live and dead rows per
 * block.  The previous sampling method put too much credence in the row
 * density near the start of the table.
 */
static int
acquire_sample_rows(Relation onerel, int elevel,
                    HeapTuple *rows, int targrows,
                    double *totalrows, double *totaldeadrows)
{
    // ...

    /* Outer loop over blocks to sample */
    while (BlockSampler_HasMore(&bs))
    {
        bool        block_accepted;
        BlockNumber targblock = BlockSampler_Next(&bs);
        // ...
    }

    // ...

    /*
     * If we didn't find as many tuples as we wanted then we're done. No sort
     * is needed, since they're already in order.
     *
     * Otherwise we need to sort the collected tuples by position
     * (itempointer). It's not worth worrying about corner cases where the
     * tuples are already sorted.
     */
    if (numrows == targrows)
        qsort((void *) rows, numrows, sizeof(HeapTuple), compare_rows);

    /*
     * Estimate total numbers of live and dead rows in relation, extrapolating
     * on the assumption that the average tuple density in pages we didn't
     * scan is the same as in the pages we did scan.  Since what we scanned is
     * a random sample of the pages in the relation, this should be a good
     * assumption.
     */
    if (bs.m > 0)
    {
        *totalrows = floor((liverows / bs.m) * totalblocks + 0.5);
        *totaldeadrows = floor((deadrows / bs.m) * totalblocks + 0.5);
    }
    else
    {
        *totalrows = 0.0;
        *totaldeadrows = 0.0;
    }

    // ...
}
```

å›åˆ° `do_analyze_rel()` å‡½æ•°ã€‚é‡‡æ ·åˆ°æ•°æ®ä»¥åï¼Œå¯¹äºè¦åˆ†æçš„æ¯ä¸€ä¸ªåˆ—ï¼Œåˆ†åˆ«è®¡ç®—ç»Ÿè®¡æ•°æ®ï¼Œç„¶åæ›´æ–° `pg_statistic` ç³»ç»Ÿè¡¨ï¼š

```c
/*
 * Compute the statistics.  Temporary results during the calculations for
 * each column are stored in a child context.  The calc routines are
 * responsible to make sure that whatever they store into the VacAttrStats
 * structure is allocated in anl_context.
 */
if (numrows > 0)
{
    // ...

    for (i = 0; i < attr_cnt; i++)
    {
        VacAttrStats *stats = vacattrstats[i];
        AttributeOpts *aopt;

        stats->rows = rows;
        stats->tupDesc = onerel->rd_att;
        stats->compute_stats(stats,
                             std_fetch_func,
                             numrows,
                             totalrows);

        // ...
    }

    // ...

    /*
     * Emit the completed stats rows into pg_statistic, replacing any
     * previous statistics for the target columns.  (If there are stats in
     * pg_statistic for columns we didn't process, we leave them alone.)
     */
    update_attstats(RelationGetRelid(onerel), inh,
                    attr_cnt, vacattrstats);

    // ...
}
```

æ˜¾ç„¶ï¼Œå¯¹äºä¸åŒç±»å‹çš„åˆ—ï¼Œå…¶ `compute_stats` å‡½æ•°æŒ‡é’ˆæŒ‡å‘çš„è®¡ç®—å‡½æ•°è‚¯å®šä¸å¤ªä¸€æ ·ã€‚æ‰€ä»¥æˆ‘ä»¬ä¸å¦¨çœ‹çœ‹ç»™è¿™ä¸ªå‡½æ•°æŒ‡é’ˆèµ‹å€¼çš„åœ°æ–¹ï¼š

```c
/*
 * std_typanalyze -- the default type-specific typanalyze function
 */
bool
std_typanalyze(VacAttrStats *stats)
{
    // ...

    /*
     * Determine which standard statistics algorithm to use
     */
    if (OidIsValid(eqopr) && OidIsValid(ltopr))
    {
        /* Seems to be a scalar datatype */
        stats->compute_stats = compute_scalar_stats;
        /*--------------------
         * The following choice of minrows is based on the paper
         * "Random sampling for histogram construction: how much is enough?"
         * by Surajit Chaudhuri, Rajeev Motwani and Vivek Narasayya, in
         * Proceedings of ACM SIGMOD International Conference on Management
         * of Data, 1998, Pages 436-447.  Their Corollary 1 to Theorem 5
         * says that for table size n, histogram size k, maximum relative
         * error in bin size f, and error probability gamma, the minimum
         * random sample size is
         *      r = 4 * k * ln(2*n/gamma) / f^2
         * Taking f = 0.5, gamma = 0.01, n = 10^6 rows, we obtain
         *      r = 305.82 * k
         * Note that because of the log function, the dependence on n is
         * quite weak; even at n = 10^12, a 300*k sample gives <= 0.66
         * bin size error with probability 0.99.  So there's no real need to
         * scale for n, which is a good thing because we don't necessarily
         * know it at this point.
         *--------------------
         */
        stats->minrows = 300 * attr->attstattarget;
    }
    else if (OidIsValid(eqopr))
    {
        /* We can still recognize distinct values */
        stats->compute_stats = compute_distinct_stats;
        /* Might as well use the same minrows as above */
        stats->minrows = 300 * attr->attstattarget;
    }
    else
    {
        /* Can't do much but the trivial stuff */
        stats->compute_stats = compute_trivial_stats;
        /* Might as well use the same minrows as above */
        stats->minrows = 300 * attr->attstattarget;
    }

    // ...
}
```

è¿™ä¸ªæ¡ä»¶åˆ¤æ–­è¯­å¥å¯ä»¥è¢«è§£è¯»ä¸ºï¼š

- å¦‚æœè¯´ä¸€ä¸ªåˆ—çš„æ•°æ®ç±»å‹æ”¯æŒé»˜è®¤çš„ `=`ï¼ˆ`eqopr`ï¼šequals operatorï¼‰å’Œ `<`ï¼ˆ`ltopr`ï¼šless than operatorï¼‰ï¼Œé‚£ä¹ˆè¿™ä¸ªåˆ—åº”è¯¥æ˜¯ä¸€ä¸ªæ•°å€¼ç±»å‹ï¼Œå¯ä»¥ä½¿ç”¨ `compute_scalar_stats()` å‡½æ•°è¿›è¡Œåˆ†æ
- å¦‚æœåˆ—çš„æ•°æ®ç±»å‹åªæ”¯æŒ `=` è¿ç®—ç¬¦ï¼Œé‚£ä¹ˆä¾æ—§è¿˜å¯ä»¥ä½¿ç”¨ `compute_distinct_stats` è¿›è¡Œå”¯ä¸€å€¼çš„ç»Ÿè®¡åˆ†æ
- å¦‚æœéƒ½ä¸è¡Œï¼Œé‚£ä¹ˆè¿™ä¸ªåˆ—åªèƒ½ä½¿ç”¨ `compute_trivial_stats` è¿›è¡Œä¸€äº›ç®€å•çš„åˆ†æ

æˆ‘ä»¬å¯ä»¥åˆ†åˆ«çœ‹çœ‹è¿™ä¸‰ä¸ªåˆ†æå‡½æ•°é‡Œåšäº†å•¥ï¼Œä½†æˆ‘ä¸å‡†å¤‡æ·±å…¥æ¯ä¸€ä¸ªåˆ†æå‡½æ•°è§£è¯»å…¶ä¸­çš„é€»è¾‘äº†ã€‚å› ä¸ºå…¶ä¸­çš„æ€æƒ³åŸºäºä¸€äº›å¾ˆå¤æ—©çš„ç»Ÿè®¡å­¦è®ºæ–‡ï¼Œå¤æ—©åˆ°è¿ PDF ä¸Šçš„å­—æ¯éƒ½å¿«çœ‹ä¸æ¸…äº†...ğŸ˜± å’±æ•°å­¦ä¸å¥½ï¼Œå·ä¸ªæ‡’ã€‚åœ¨ä»£ç ä¸Šæ²¡æœ‰ç‰¹åˆ«å¤§çš„å¯è¯»æ€§ï¼Œå› ä¸ºåŸºæœ¬æ˜¯å‚ç…§è®ºæ–‡ä¸­çš„å…¬å¼å®ç°çš„ï¼Œä¸çœ‹è®ºæ–‡æ ¹æœ¬æ²¡æ³•ç†è§£å˜é‡å’Œå…¬å¼çš„å«ä¹‰ã€‚

### compute_trivial_stats

å¦‚æœæŸä¸ªåˆ—çš„æ•°æ®ç±»å‹ä¸æ”¯æŒç­‰å€¼è¿ç®—ç¬¦å’Œæ¯”è¾ƒè¿ç®—ç¬¦ï¼Œé‚£ä¹ˆå°±åªèƒ½è¿›è¡Œä¸€äº›ç®€å•çš„åˆ†æï¼Œæ¯”å¦‚ï¼š

- éç©ºè¡Œçš„æ¯”ä¾‹
- åˆ—ä¸­å…ƒç»„çš„å¹³å‡å®½åº¦

è¿™äº›å¯ä»¥é€šè¿‡å¯¹é‡‡æ ·åçš„å…ƒç»„æ•°ç»„è¿›è¡Œå¾ªç¯éå†åè½»æ¾å¾—åˆ°ã€‚

```c
/*
 *  compute_trivial_stats() -- compute very basic column statistics
 *
 *  We use this when we cannot find a hash "=" operator for the datatype.
 *
 *  We determine the fraction of non-null rows and the average datum width.
 */
static void
compute_trivial_stats(VacAttrStatsP stats,
                      AnalyzeAttrFetchFunc fetchfunc,
                      int samplerows,
                      double totalrows)
{}
```

### compute_distinct_stats

å¦‚æœæŸä¸ªåˆ—åªæ”¯æŒç­‰å€¼è¿ç®—ç¬¦ï¼Œä¹Ÿå°±æ˜¯è¯´æˆ‘ä»¬åªèƒ½çŸ¥é“ä¸€ä¸ªæ•°å€¼ **æ˜¯ä»€ä¹ˆ**ï¼Œä½†ä¸èƒ½å’Œå…¶å®ƒæ•°å€¼æ¯”å¤§å°ã€‚æ‰€ä»¥æ— æ³•åˆ†ææ•°å€¼åœ¨å¤§å°èŒƒå›´ä¸Šçš„åˆ†å¸ƒï¼Œåªèƒ½åˆ†ææ•°å€¼åœ¨å‡ºç°é¢‘ç‡ä¸Šçš„åˆ†å¸ƒã€‚æ‰€ä»¥è¯¥å‡½æ•°åˆ†æçš„ç»Ÿè®¡æ•°æ®åŒ…å«ï¼š

- éç©ºè¡Œçš„æ¯”ä¾‹
- åˆ—ä¸­å…ƒç»„çš„å¹³å‡å®½åº¦
- æœ€é¢‘ç¹å‡ºç°çš„å€¼ï¼ˆMCVï¼‰
- ï¼ˆä¼°ç®—çš„ï¼‰å”¯ä¸€å€¼ä¸ªæ•°

```c
/*
 *  compute_distinct_stats() -- compute column statistics including ndistinct
 *
 *  We use this when we can find only an "=" operator for the datatype.
 *
 *  We determine the fraction of non-null rows, the average width, the
 *  most common values, and the (estimated) number of distinct values.
 *
 *  The most common values are determined by brute force: we keep a list
 *  of previously seen values, ordered by number of times seen, as we scan
 *  the samples.  A newly seen value is inserted just after the last
 *  multiply-seen value, causing the bottommost (oldest) singly-seen value
 *  to drop off the list.  The accuracy of this method, and also its cost,
 *  depend mainly on the length of the list we are willing to keep.
 */
static void
compute_distinct_stats(VacAttrStatsP stats,
                       AnalyzeAttrFetchFunc fetchfunc,
                       int samplerows,
                       double totalrows)
{}
```

### compute_scalar_stats

å¦‚æœä¸€ä¸ªåˆ—çš„æ•°æ®ç±»å‹æ”¯æŒç­‰å€¼è¿ç®—ç¬¦å’Œæ¯”è¾ƒè¿ç®—ç¬¦ï¼Œé‚£ä¹ˆå¯ä»¥è¿›è¡Œæœ€è¯¦å°½çš„åˆ†æã€‚åˆ†æç›®æ ‡åŒ…å«ï¼š

- éç©ºè¡Œçš„æ¯”ä¾‹
- åˆ—ä¸­å…ƒç»„çš„å¹³å‡å®½åº¦
- æœ€é¢‘ç¹å‡ºç°çš„å€¼ï¼ˆMCVï¼‰
- ï¼ˆä¼°ç®—çš„ï¼‰å”¯ä¸€å€¼ä¸ªæ•°
- æ•°æ®åˆ†å¸ƒç›´æ–¹å›¾
- ç‰©ç†å’Œé€»è¾‘ä½ç½®çš„ç›¸å…³æ€§ï¼ˆè¿™ä¸ªæ˜¯ç”¨æ¥å¹²å•¥çš„ï¼Ÿï¼Ÿï¼ŸğŸ˜¥ï¼‰

```c
/*
 *  compute_distinct_stats() -- compute column statistics including ndistinct
 *
 *  We use this when we can find only an "=" operator for the datatype.
 *
 *  We determine the fraction of non-null rows, the average width, the
 *  most common values, and the (estimated) number of distinct values.
 *
 *  The most common values are determined by brute force: we keep a list
 *  of previously seen values, ordered by number of times seen, as we scan
 *  the samples.  A newly seen value is inserted just after the last
 *  multiply-seen value, causing the bottommost (oldest) singly-seen value
 *  to drop off the list.  The accuracy of this method, and also its cost,
 *  depend mainly on the length of the list we are willing to keep.
 */
static void
compute_distinct_stats(VacAttrStatsP stats,
                       AnalyzeAttrFetchFunc fetchfunc,
                       int samplerows,
                       double totalrows)
{}
```

## Summary

ä»¥ PostgreSQL ä¼˜åŒ–å™¨éœ€è¦çš„ç»Ÿè®¡ä¿¡æ¯ä¸ºåˆ‡å…¥ç‚¹ï¼Œåˆ†æäº† `ANALYZE` å‘½ä»¤çš„å¤§è‡´æ‰§è¡Œæµç¨‹ã€‚å‡ºäºç®€æ´æ€§ï¼Œåœ¨æµç¨‹åˆ†æä¸Šæ²¡æœ‰è¦†ç›–å„ç§ corner case å’Œç›¸å…³çš„å¤„ç†é€»è¾‘ã€‚åŒæ—¶é¿å¼€äº†æ‰€æœ‰å’Œæ•°å­¦ç›¸å…³çš„ç»†èŠ‚ ğŸ¤ªã€‚

## References

[PostgreSQL 14 Documentation: ANALYZE](https://www.postgresql.org/docs/current/sql-analyze.html)

[PostgreSQL 14 Documentation: 25.1. Routine Vacuuming](https://www.postgresql.org/docs/current/routine-vacuuming.html#VACUUM-FOR-STATISTICS)

[PostgreSQL 14 Documentation: 14.2. Statistics Used by the Planner](https://www.postgresql.org/docs/current/planner-stats.html)

[PostgreSQL 14 Documentation: 52.49. pg_statistic](https://www.postgresql.org/docs/current/catalog-pg-statistic.html)

[é˜¿é‡Œäº‘æ•°æ®åº“å†…æ ¸æœˆæŠ¥ 2016/05ï¼šPostgreSQL ç‰¹æ€§åˆ†æ ç»Ÿè®¡ä¿¡æ¯è®¡ç®—æ–¹æ³•](http://mysql.taobao.org/monthly/2016/05/09/)
